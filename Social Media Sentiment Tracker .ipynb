{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1p2VV_Tk4gb",
        "outputId": "d14f7105-cfe0-4cc9-f966-56d5e5403413"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.7.14)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "# installing kaggle library\n",
        "! pip install kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# upload your kaggle.json file"
      ],
      "metadata": {
        "id": "4xdw5GQbpHra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# configuring the path of kaggle.json file\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "QCRGi39PpCpp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# impoting twitter sentiment dataset"
      ],
      "metadata": {
        "id": "VT1K8UsgrJQM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d kazanova/sentiment140"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwRi9aGnrQK3",
        "outputId": "5adbeedc-9e71-4bda-fac6-ceab2a42764b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/kazanova/sentiment140\n",
            "License(s): other\n",
            "Downloading sentiment140.zip to /content\n",
            "  0% 0.00/80.9M [00:00<?, ?B/s]\n",
            "100% 80.9M/80.9M [00:00<00:00, 1.17GB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting a compressed dataset\n",
        "\n",
        "from zipfile import ZipFile\n",
        "dataset = '/content/sentiment140.zip'\n",
        "\n",
        "with ZipFile(dataset, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('The dataset is extracted')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2rACZootL5T",
        "outputId": "3d0b99a1-da65-4fb6-a93d-0463524448f2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dataset is extracted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# importing the dependencies"
      ],
      "metadata": {
        "id": "0IpOlyCguaZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "niKIwrRLuVEx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOWB4fowx2EM",
        "outputId": "d0652654-3963-4ecd-b953-e31d7737694d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#printing the stopwords in english\n",
        "print(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LM7_947yIjq",
        "outputId": "f25c3800-ae75-48f9-cec3-5bed037cb515"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# data processing"
      ],
      "metadata": {
        "id": "-9Rl9KjyzQZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the data from csv file to pandas dataframe\n",
        "twitter_data = pd.read_csv('/content/training.1600000.processed.noemoticon.csv',encoding = 'ISO-8859-1')"
      ],
      "metadata": {
        "id": "lm8Z_ZsEzU-u"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the number of rows and columns\n",
        "twitter_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FS-xlwB60NjG",
        "outputId": "43f10db9-5285-4030-c9f7-1d82e49ef634"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1599999, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# install necessary libraries"
      ],
      "metadata": {
        "id": "FPl3537e1CBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas scikit-learn\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5zIHyVM1Gjr",
        "outputId": "21a6a6a1-f2e7-4a00-cc51-9ed7150377a4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# load dataset"
      ],
      "metadata": {
        "id": "2kk2EEyG1cpg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('training.1600000.processed.noemoticon.csv', encoding='latin-1', header=None)\n",
        "df = df[[0, 5]]\n",
        "df.columns = ['polarity', 'text']\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQb-7UjY1fgc",
        "outputId": "b20e46b5-ce26-4deb-ed4e-b0a84aeea853"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   polarity                                               text\n",
            "0         0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
            "1         0  is upset that he can't update his Facebook by ...\n",
            "2         0  @Kenichan I dived many times for the ball. Man...\n",
            "3         0    my whole body feels itchy and like its on fire \n",
            "4         0  @nationwideclass no, it's not behaving at all....\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# keep only positive and negative sentiments"
      ],
      "metadata": {
        "id": "_tqoVwQ811_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df.polarity != 2]\n",
        "\n",
        "df['polarity'] = df['polarity'].map({0: 0, 4: 1})\n",
        "\n",
        "print(df['polarity'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RELA0-Y11-6b",
        "outputId": "a4001b1f-15aa-48d5-f0e1-b07dcb127834"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "polarity\n",
            "0    800000\n",
            "1    800000\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# clean the tweets"
      ],
      "metadata": {
        "id": "jAK4yfAD2IlB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    return text.lower()\n",
        "\n",
        "df['clean_text'] = df['text'].apply(clean_text)\n",
        "\n",
        "print(df[['text', 'clean_text']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7dZFKcS2MZZ",
        "outputId": "1ab26c9f-462e-4ffe-d687-e92c87122f79"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text                                         clean_text\n",
            "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  @switchfoot http://twitpic.com/2y1zl - awww, t...\n",
            "1  is upset that he can't update his Facebook by ...  is upset that he can't update his facebook by ...\n",
            "2  @Kenichan I dived many times for the ball. Man...  @kenichan i dived many times for the ball. man...\n",
            "3    my whole body feels itchy and like its on fire     my whole body feels itchy and like its on fire \n",
            "4  @nationwideclass no, it's not behaving at all....  @nationwideclass no, it's not behaving at all....\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Test Split"
      ],
      "metadata": {
        "id": "OS0jOdeo2YAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['clean_text'],\n",
        "    df['polarity'],\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Train size:\", len(X_train))\n",
        "print(\"Test size:\", len(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTodbBDy2gGr",
        "outputId": "9b86ec7b-20a6-4f08-d52a-2e8769cca5a7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 1280000\n",
            "Test size: 320000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perform Vectorization"
      ],
      "metadata": {
        "id": "1VPlzHjc2p_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
        "\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "print(\"TF-IDF shape (train):\", X_train_tfidf.shape)\n",
        "print(\"TF-IDF shape (test):\", X_test_tfidf.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_-SDShM2vWi",
        "outputId": "3a7bfe4e-94ba-404f-dcc6-b09d4dffcc47"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF shape (train): (1280000, 5000)\n",
            "TF-IDF shape (test): (320000, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Bernoulli Naive Bayes model"
      ],
      "metadata": {
        "id": "erUnr7Yv3N2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bnb = BernoulliNB()\n",
        "bnb.fit(X_train_tfidf, y_train)\n",
        "\n",
        "bnb_pred = bnb.predict(X_test_tfidf)\n",
        "\n",
        "print(\"Bernoulli Naive Bayes Accuracy:\", accuracy_score(y_test, bnb_pred))\n",
        "print(\"\\nBernoulliNB Classification Report:\\n\", classification_report(y_test, bnb_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJ1TeBFQ3XGj",
        "outputId": "d33dd014-3657-4cbf-cb32-3f4b8a4826d3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bernoulli Naive Bayes Accuracy: 0.766478125\n",
            "\n",
            "BernoulliNB Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.75      0.76    159494\n",
            "           1       0.76      0.78      0.77    160506\n",
            "\n",
            "    accuracy                           0.77    320000\n",
            "   macro avg       0.77      0.77      0.77    320000\n",
            "weighted avg       0.77      0.77      0.77    320000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Support Vector Machine(SVM)model"
      ],
      "metadata": {
        "id": "R3EV1iy43hAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm = LinearSVC(max_iter=1000)\n",
        "svm.fit(X_train_tfidf, y_train)\n",
        "\n",
        "svm_pred = svm.predict(X_test_tfidf)\n",
        "\n",
        "print(\"SVM Accuracy:\", accuracy_score(y_test, svm_pred))\n",
        "print(\"\\nSVM Classification Report:\\n\", classification_report(y_test, svm_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iA-yY9e_3rB5",
        "outputId": "1c895fe9-06ea-462d-ae81-d11a7a3b02c4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.79528125\n",
            "\n",
            "SVM Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.78      0.79    159494\n",
            "           1       0.79      0.81      0.80    160506\n",
            "\n",
            "    accuracy                           0.80    320000\n",
            "   macro avg       0.80      0.80      0.80    320000\n",
            "weighted avg       0.80      0.80      0.80    320000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Logistic Regression model"
      ],
      "metadata": {
        "id": "hQ45B-E24H4E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logreg = LogisticRegression(max_iter=100)\n",
        "logreg.fit(X_train_tfidf, y_train)\n",
        "\n",
        "logreg_pred = logreg.predict(X_test_tfidf)\n",
        "\n",
        "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, logreg_pred))\n",
        "print(\"\\nLogistic Regression Classification Report:\\n\", classification_report(y_test, logreg_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_MPS-Ck4Q-Z",
        "outputId": "5bb83a62-f29a-4dfd-ec08-e23164f01f40"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 0.79539375\n",
            "\n",
            "Logistic Regression Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.78      0.79    159494\n",
            "           1       0.79      0.81      0.80    160506\n",
            "\n",
            "    accuracy                           0.80    320000\n",
            "   macro avg       0.80      0.80      0.80    320000\n",
            "weighted avg       0.80      0.80      0.80    320000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make Predictions on Sample tweets"
      ],
      "metadata": {
        "id": "yCkx3Pkj4eTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_tweets = [\"I love this!\", \"I hate that!\", \"It was okay, not great.\"]\n",
        "sample_vec = vectorizer.transform(sample_tweets)\n",
        "\n",
        "print(\"\\nSample Predictions:\")\n",
        "print(\"BernoulliNB:\", bnb.predict(sample_vec))\n",
        "print(\"SVM:\", svm.predict(sample_vec))\n",
        "print(\"Logistic Regression:\", logreg.predict(sample_vec))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLm92wC34lw5",
        "outputId": "6fc5f7df-5822-4339-c7b1-d3341b1edbd8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample Predictions:\n",
            "BernoulliNB: [1 0 1]\n",
            "SVM: [1 0 1]\n",
            "Logistic Regression: [1 0 1]\n"
          ]
        }
      ]
    }
  ]
}